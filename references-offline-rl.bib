@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}


@article{dudik2011doubly,
  title={Doubly robust policy evaluation and learning},
  author={Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  journal={arXiv preprint arXiv:1103.4601},
  year={2011}
}

@article{su2019doubly,
  title={Doubly robust off-policy evaluation with shrinkage},
  author={Su, Yi and Dimakopoulou, Maria and Krishnamurthy, Akshay and Dud{\'\i}k, Miroslav},
  journal={arXiv preprint arXiv:1907.09623},
  year={2019}
}


@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@misc{
yang2019convergent,
title={Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective},
author={Zhuoran Yang and Zuyue Fu and Kaiqing Zhang and Zhaoran Wang},
year={2019},
url={https://openreview.net/forum?id=ryfcCo0ctQ},
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{agarwal2019optimality,
  title={Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={arXiv preprint arXiv:1908.00261},
  year={2019}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{ahmed2019understanding,
  title={Understanding the impact of entropy on policy optimization},
  author={Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={151--160},
  year={2019}
}

@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}

@misc{hernan2010causal,
  title={Causal inference},
  author={Hernan, Miguel A and Robins, James M}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{bertsekas1995dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P},
  volume={2},
  year={1995},
  publisher={Athena scientific Belmont, MA}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@article{haarnoja2018soft1,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{haarnoja2018soft2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{zhang2019residual,
  author    = {Shangtong Zhang and
               Wendelin Boehmer and
               Shimon Whiteson},
  title     = {Deep Residual Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1905.01072},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.01072},
  archivePrefix = {arXiv},
  eprint    = {1905.01072},
  timestamp = {Mon, 27 May 2019 13:15:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-01072},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{li2008worst,
  title={A worst-case comparison between temporal difference and residual gradient with linear function approximation},
  author={Li, Lihong},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={560--567},
  year={2008},
  organization={ACM}
}

@article{schapire1996worst,
  title={On the worst-case analysis of temporal-difference learning algorithms},
  author={Schapire, Robert E and Warmuth, Manfred K},
  journal={Machine Learning},
  volume={22},
  number={1-3},
  pages={95--121},
  year={1996},
  publisher={Springer}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@inproceedings{lu2018non,
  title={Non-delusional Q-learning and value-iteration},
  author={Lu, Tyler and Schuurmans, Dale and Boutilier, Craig},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9949--9959},
  year={2018}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{du2019representation,
       author = {{Du}, Simon S. and {Kakade}, Sham M. and {Wang}, Ruosong and
         {Yang}, Lin F.},
        title = "{Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control, Statistics - Machine Learning},
         year = "2019",
        month = "Oct",
          eid = {arXiv:1910.03016},
        pages = {arXiv:1910.03016},
archivePrefix = {arXiv},
       eprint = {1910.03016}
}

@inproceedings{chen2019information,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  year={2019},
  organization={PMLR}
}


@article{jin2019provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  journal={arXiv preprint arXiv:1907.05388},
  year={2019}
}

@article{du2019provably,
  title={Provably Efficient $ Q $-learning with Function Approximation via Distribution Shift Error Checking Oracle},
  author={Du, Simon S and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
  journal={arXiv preprint arXiv:1906.06321},
  year={2019}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low Bellman rank are PAC-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1704--1713},
  year={2017},
  organization={JMLR. org}
}


@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gellert},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@article{fujimoto2019benchmarking,
  title={Benchmarking Batch Deep Reinforcement Learning Algorithms},
  author={Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
  journal={arXiv preprint arXiv:1910.01708},
  year={2019}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}


@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}


@inproceedings{chen2019surrogate,
  title={Surrogate Objectives for Batch Policy Optimization in One-step Decision Making},
  author={Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8825--8835},
  year={2019}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{ma2019imitation,
  title={Imitation-Regularized Offline Learning},
  author={Ma, Yifei and Wang, Yu-Xiang and others},
  journal={arXiv preprint arXiv:1901.04723},
  year={2019}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@article{johansson2018learning,
  title={Learning weighted representations for generalization across designs},
  author={Johansson, Fredrik D and Kallus, Nathan and Shalit, Uri and Sontag, David},
  journal={arXiv preprint arXiv:1802.08598},
  year={2018}
}

@inproceedings{kallus2018balanced,
  title={Balanced policy evaluation and learning},
  author={Kallus, Nathan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8895--8906},
  year={2018}
}

@article{Johansson2020GeneralizationBA,
  title={Generalization Bounds and Representation Learning for Estimation of Potential Outcomes and Causal Effects},
  author={Fredrik D. Johansson and Uri Shalit and Nathan Kallus and David Sontag},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.07426}
}

@article{byrd2018effect,
  title={What is the Effect of Importance Weighting in Deep Learning?},
  author={Byrd, Jonathon and Lipton, Zachary C},
  journal={arXiv preprint arXiv:1812.03372},
  year={2018}
}

@article{gretton2009covariate,
  title={Covariate shift by kernel mean matching},
  author={Gretton, Arthur and Smola, Alex and Huang, Jiayuan and Schmittfull, Marcel and Borgwardt, Karsten and Sch{\"o}lkopf, Bernhard},
  year={2009}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bach2017breaking,
  title={Breaking the curse of dimensionality with convex neural networks},
  author={Bach, Francis},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={629--681},
  year={2017},
  publisher={JMLR. org}
}

@article{guruswami2009hardness,
  title={Hardness of learning halfspaces with noise},
  author={Guruswami, Venkatesan and Raghavendra, Prasad},
  journal={SIAM Journal on Computing},
  volume={39},
  number={2},
  pages={742--765},
  year={2009},
  publisher={SIAM}
}

@inproceedings{belkin2018overfitting,
  title={Overfitting or perfect fitting? risk bounds for classification and regression rules that interpolate},
  author={Belkin, Mikhail and Hsu, Daniel J and Mitra, Partha},
  booktitle={Advances in neural information processing systems},
  pages={2300--2311},
  year={2018}
}

@article{liang2018just,
  title={Just interpolate: Kernel" ridgeless" regression can generalize},
  author={Liang, Tengyuan and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:1808.00387},
  year={2018}
}

@article{belkin2018does,
  title={Does data interpolation contradict statistical optimality?},
  author={Belkin, Mikhail and Rakhlin, Alexander and Tsybakov, Alexandre B},
  journal={arXiv preprint arXiv:1806.09471},
  year={2018}
}

@article{bartlett2006convexity,
  title={Convexity, classification, and risk bounds},
  author={Bartlett, Peter L and Jordan, Michael I and McAuliffe, Jon D},
  journal={Journal of the American Statistical Association},
  volume={101},
  number={473},
  pages={138--156},
  year={2006},
  publisher={Taylor \& Francis}
}

@inproceedings{pires2013cost,
  title={Cost-sensitive multiclass classification risk bounds},
  author={Pires, Bernardo Avila and Szepesvari, Csaba and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={1391--1399},
  year={2013}
}

@inproceedings{auer1996exponentially,
  title={Exponentially many local minima for single neurons},
  author={Auer, Peter and Herbster, Mark and Warmuth, Manfred KK},
  booktitle={Advances in neural information processing systems},
  pages={316--322},
  year={1996}
}

@article{rosasco2004loss,
  title={Are loss functions all the same?},
  author={Rosasco, Lorenzo and Vito, Ernesto De and Caponnetto, Andrea and Piana, Michele and Verri, Alessandro},
  journal={Neural Computation},
  volume={16},
  number={5},
  pages={1063--1076},
  year={2004},
  publisher={MIT Press}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{agarwal2019optimistic,
  title={An Optimistic Perspective on Offline Reinforcement Learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  year={2019}
}

@article{athey2017efficient,
  title={Efficient policy learning},
  author={Athey, Susan and Wager, Stefan},
  journal={arXiv preprint arXiv:1702.02896},
  year={2017}
}

@article{zhou2018offline,
  title={Offline multi-action policy learning: Generalization and optimization},
  author={Zhou, Zhengyuan and Athey, Susan and Wager, Stefan},
  journal={arXiv preprint arXiv:1810.04778},
  year={2018}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th International Conference on World Wide Web},
  pages={661--670},
  year={2010}
}

@article{nakkiran2019deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1912.02292},
  year={2019}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@inproceedings{guez2008adaptive,
  title={Adaptive treatment of epilepsy via batch-mode reinforcement learning},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={Proceedings of the 20th national conference on Innovative applications of artificial intelligence-Volume 3},
  pages={1671--1678},
  year={2008}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{shimodaira2000improving,
  title={Improving predictive inference under covariate shift by weighting the log-likelihood function},
  author={Shimodaira, Hidetoshi},
  journal={Journal of statistical planning and inference},
  volume={90},
  number={2},
  pages={227--244},
  year={2000},
  publisher={Elsevier}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@article{su2018cab,
  title={Cab: Continuous adaptive blending estimator for policy evaluation and learning},
  author={Su, Yi and Wang, Lequn and Santacatterina, Michele and Joachims, Thorsten},
  journal={arXiv preprint arXiv:1811.02672},
  year={2018}
}

@inproceedings{Domingos2000AUB,
  title={A Unified Bias-Variance Decomposition and its Applications},
  author={P. Domingos},
  year={2000}
}

@inproceedings{bottou2008tradeoffs,
  title={The tradeoffs of large scale learning},
  author={Bottou, L{\'e}on and Bousquet, Olivier},
  booktitle={Advances in neural information processing systems},
  pages={161--168},
  year={2008}
}


@inproceedings{belkin2019does,
  title={Does data interpolation contradict statistical optimality?},
  author={Belkin, Mikhail and Rakhlin, Alexander and Tsybakov, Alexandre B},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1611--1619},
  year={2019},
  organization={PMLR}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@InProceedings{agarwal20optimality, title = {Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes}, author = {Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav}, pages = {64--66}, year = {2020}, editor = {Jacob Abernethy and Shivani Agarwal}, volume = {125}, series = {Proceedings of Machine Learning Research}, address = {}, month = {09--12 Jul}, publisher = {PMLR}}

@inproceedings{
Du2020Is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020}
}

@InProceedings{riedmiller18a, title = {Learning by Playing Solving Sparse Reward Tasks from Scratch}, author = {Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and van de Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias}, pages = {4344--4353}, year = {2018}, editor = {Jennifer Dy and Andreas Krause}, volume = {80}, series = {Proceedings of Machine Learning Research}, address = {Stockholmsmässan, Stockholm Sweden}, month = {10--15 Jul}, publisher = {PMLR} }

@article{zanette2020learning,
  title={Learning Near Optimal Policies with Low Inherent Bellman Error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  journal={arXiv preprint arXiv:2003.00153},
  year={2020}
}

@article{misra2019kinematic,
  title={Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  journal={arXiv preprint arXiv:1911.05815},
  year={2019}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@book{osa2018alg,
author = {Osa, Takayuki and Pajarinen, Joni and Neumann, Gerhard},
title = {An Algorithmic Perspective on Imitation Learning},
year = {2018},
isbn = {168083410X},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
}

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}


@inproceedings{weaver2001,
author = {Weaver, Lex and Tao, Nigel},
title = {The Optimal Reward Baseline for Gradient-Based Reinforcement Learning},
year = {2001},
isbn = {1558608001},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {There exist a number of reinforcement learning algorithms which learn by climbing the gradient of expected reward. Their long-run convergence has been proved, even in partially observable environments with non-deterministic actions, and without the need for a system model. However, the variance of the gradient estimator has been found to be a significant practical problem. Recent approaches have discounted future rewards, introducing a bias-variance trade-off into the gradient estimate. We incorporate a reward baseline into the learning system, and show that it affects variance without introducing further bias. In particular, as we approach the zerobias, high-variance parametedzation, the optimal (or variance minimizing) constant reward baseline is equal to the long-term average expected reward. Modified policy-gradient algorithms are presented, and a number of experiments demonstrate their improvement over previous work.},
booktitle = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
pages = {538–545},
numpages = {8},
location = {Seattle, Washington},
series = {UAI'01}
}

@article{greensmith2004variance,
  title={Variance reduction techniques for gradient estimates in reinforcement learning},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Nov},
  pages={1471--1530},
  year={2004}
}

@ARTICLE{cover1967,
  author={T. {Cover} and P. {Hart}},
  journal={IEEE Transactions on Information Theory},
  title={Nearest neighbor pattern classification},
  year={1967},
  volume={13},
  number={1},
  pages={21-27},}

@article{chatterji2020finite,
  title={Finite-sample analysis of interpolating linear classifiers in the overparameterized regime},
  author={Chatterji, Niladri S and Long, Philip M},
  journal={arXiv preprint arXiv:2004.12019},
  year={2020}
}

@article{bartlett2020benign,
  title={Benign overfitting in linear regression},
  author={Bartlett, Peter L and Long, Philip M and Lugosi, G{\'a}bor and Tsigler, Alexander},
  journal={Proceedings of the National Academy of Sciences},
  year={2020},
  publisher={National Acad Sciences}
}

@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in neural information processing systems},
  pages={8026--8037},
  year={2019}
}

@inproceedings{langford2008epoch,
  title={The epoch-greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  booktitle={Advances in neural information processing systems},
  pages={817--824},
  year={2008}
}

@software{miller2020whynot,
  author       = {John Miller and
                  Chloe Hsu and
                  Jordan Troutman and
                  Juan Perdomo and
                  Tijana Zrnic and
                  Lydia Liu and
                  Yu Sun and
                  Ludwig Schmidt and
                  Moritz Hardt},
  title        = {WhyNot},
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3875775},
  url          = {https://doi.org/10.5281/zenodo.3875775}
}

@article{soudry2018,
author = {Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
title = {The Implicit Bias of Gradient Descent on Separable Data},
year = {2018},
issue_date = {January 2018},
publisher = {JMLR.org},
volume = {19},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2822–2878},
numpages = {57},
keywords = {implicit regularization, gradient descent, margin, logistic regression, generalization}
}


@article{ji2018gradient,
  title={Gradient descent aligns the layers of deep linear networks},
  author={Ji, Ziwei and Telgarsky, Matus},
  journal={arXiv preprint arXiv:1810.02032},
  year={2018}
}

@article{Prasad2017ARL,
  title={A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units},
  author={N. Prasad and Li-Fang Cheng and C. Chivers and Michael Draugelis and B. Engelhardt},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.06300}
}

@article{Raghu2017DeepRL,
  title={Deep Reinforcement Learning for Sepsis Treatment},
  author={Aniruddh Raghu and M. Komorowski and I. Ahmed and L. A. Celi and Peter Szolovits and M. Ghassemi},
  journal={ArXiv},
  year={2017},
  volume={abs/1711.09602}
}

@inproceedings{nagarajan2019uniform,
  title={Uniform convergence may be unable to explain generalization in deep learning},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11615--11626},
  year={2019}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@book{vapnik1982,
author = {Vapnik, Vladimir},
title = {Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)},
year = {1982},
isbn = {0387907335},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@article{cover1968estimation,
  title={Estimation by the nearest neighbor rule},
  author={Cover, T},
  journal={IEEE Transactions on Information Theory},
  volume={14},
  number={1},
  pages={50--55},
  year={1968},
  publisher={IEEE}
}

@inproceedings{
Brandfonbrener2020Geometric,
title={Geometric Insights into the Convergence of Nonlinear TD Learning},
author={David Brandfonbrener and Joan Bruna},
booktitle={International Conference on Learning Representations},
year={2020}
}

@InProceedings{pmlr-v108-zanette20a, title = {Frequentist Regret Bounds for Randomized Least-Squares Value Iteration}, author = {Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro}, pages = {1954--1964}, year = {2020}, editor = {Silvia Chiappa and Roberto Calandra}, volume = {108}, series = {Proceedings of Machine Learning Research}, address = {Online}, month = {26--28 Aug}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v108/zanette20a/zanette20a.pdf} }


@article{brandfonbrener2020bandit,
  title={Bandit Overfitting in Offline Policy Learning},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint},
  year={2020}
}


@article{Sutton1988,
 author = {Sutton, Richard S.},
 title = {Learning to Predict by the Methods of Temporal Differences},
 journal = {Mach. Learn.},
 issue_date = {August 1988},
 volume = {3},
 number = {1},
 month = aug,
 year = {1988},
 issn = {0885-6125},
 pages = {9--44},
 numpages = {36},
 acmid = {637937},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Incremental learning, connectionism, credit assignment, evaluation functions, prediction},
}


@incollection{Tsitsiklis1997,
title = {Analysis of Temporal-Diffference Learning with Function Approximation},
author = {John N. Tsitsiklis and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 9},
editor = {M. C. Mozer and M. I. Jordan and T. Petsche},
pages = {1075--1081},
year = {1997},
publisher = {MIT Press}
}

@article{russo2017tutorial,
  title={A tutorial on thompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
  journal={arXiv preprint arXiv:1707.02038},
  year={2017}
}

@article{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1703.05449},
  year={2017}
}

@article{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  journal={arXiv preprint arXiv:1806.02450},
  year={2018}
}

@article{Ollivier2018,
  author    = {Yann Ollivier},
  title     = {Approximate Temporal Difference Learning is a Gradient Descent for
               Reversible Policies},
  journal   = {CoRR},
  volume    = {abs/1805.00869},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1805.00869},
  timestamp = {Mon, 13 Aug 2018 16:48:44 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2019reinforcement,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190510389Y},
	Archiveprefix = {arXiv},
	Author = {{Yang}, Lin F. and {Wang}, Mengdi},
	Date-Added = {2020-01-15 21:20:04 +0100},
	Date-Modified = {2020-01-15 21:20:05 +0100},
	Eid = {arXiv:1905.10389},
	Eprint = {1905.10389},
	Journal = {arXiv e-prints},
	Keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	Month = {May},
	Pages = {arXiv:1905.10389},
	Primaryclass = {cs.LG},
	Title = {{Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound}},
	Year = {2019}}


@article{chung2020beyond,
  title={Beyond variance reduction: Understanding the true impact of baselines on policy optimization},
  author={Chung, Wesley and Thomas, Valentin and Machado, Marlos C and Roux, Nicolas Le},
  journal={arXiv preprint arXiv:2008.13773},
  year={2020}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{wu2018variance,
  title={Variance reduction for policy gradient with action-dependent factorized baselines},
  author={Wu, Cathy and Rajeswaran, Aravind and Duan, Yan and Kumar, Vikash and Bayen, Alexandre M and Kakade, Sham and Mordatch, Igor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1803.07246},
  year={2018}
}

@article{grathwohl2017backpropagation,
  title={Backpropagation through the void: Optimizing control variates for black-box gradient estimation},
  author={Grathwohl, Will and Choi, Dami and Wu, Yuhuai and Roeder, Geoffrey and Duvenaud, David},
  journal={arXiv preprint arXiv:1711.00123},
  year={2017}
}

@inproceedings{cheng2020trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  booktitle={Conference on Robot Learning},
  pages={1379--1394},
  year={2020}
}

@article{tucker2018mirage,
  title={The mirage of action-dependent baselines in reinforcement learning},
  author={Tucker, George and Bhupatiraju, Surya and Gu, Shixiang and Turner, Richard E and Ghahramani, Zoubin and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.10031},
  year={2018}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{chen2020bail,
  title={BAIL: Best-action imitation learning for batch deep reinforcement learning},
  author={Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Ross, Keith},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{
Siegel2020Keep,
title={Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning},
author={Noah Siegel and Jost Tobias Springenberg and Felix Berkenkamp and Abbas Abdolmaleki and Michael Neunert and Thomas Lampe and Roland Hafner and Nicolas Heess and Martin Riedmiller},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume={2},
  pages={267--274},
  year={2002}
}

@inproceedings{peters2010relative,
  title={Relative entropy policy search.},
  year={2010},
  author={Peters, Jan and M{\"u}lling, Katharina and Altun, Yasemin}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@inproceedings{laroche2019safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning},
  pages={3652--3661},
  year={2019},
  organization={PMLR}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={arXiv preprint arXiv:2006.13888},
  year={2020}
}

@article{klink2020self,
  title={Self-Paced Deep Reinforcement Learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2004.11812},
  year={2020}
}

@article{schwab2019simultaneously,
  title={Simultaneously learning vision and feature-based control policies for real-world ball-in-a-cup},
  author={Schwab, Devin and Springenberg, Tobias and Martins, Murilo F and Lampe, Thomas and Neunert, Michael and Abdolmaleki, Abbas and Hertweck, Tim and Hafner, Roland and Nori, Francesco and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1902.04706},
  year={2019}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4496--4506},
  year={2017}
}

@article{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.05300},
  year={2017}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@inproceedings{beygelzimer2009offset,
  title={The offset tree for learning with partial labels},
  author={Beygelzimer, Alina and Langford, John},
  booktitle={Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={129--138},
  year={2009}
}

@inproceedings{wang2018exponentially,
  title={Exponentially weighted imitation learning for batched historical data},
  author={Wang, Qing and Xiong, Jiechao and Han, Lei and Liu, Han and Zhang, Tong and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6288--6297},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@misc{brandfonbrener2021offline,
      title={Offline Contextual Bandits with Overparameterized Models},
      author={David Brandfonbrener and William F. Whitney and Rajesh Ranganath and Joan Bruna},
      year={2021},
      eprint={2006.15368},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{buckman2020importance,
      title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
      author={Jacob Buckman and Carles Gelada and Marc G. Bellemare},
      year={2020},
      eprint={2009.06799},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{paine2020hyperparameter,
      title={Hyperparameter Selection for Offline Reinforcement Learning},
      author={Tom Le Paine and Cosmin Paduraru and Andrea Michi and Caglar Gulcehre and Konrad Zolna and Alexander Novikov and Ziyu Wang and Nando de Freitas},
      year={2020},
      eprint={2007.09055},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2020statistical,
      title={What are the Statistical Limits of Offline RL with Linear Function Approximation?},
      author={Ruosong Wang and Dean P. Foster and Sham M. Kakade},
      year={2020},
      eprint={2010.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zanette2021exponential,
      title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
      author={Andrea Zanette},
      year={2021},
      eprint={2012.08005},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2019behavior,
      title={Behavior Regularized Offline Reinforcement Learning},
      author={Yifan Wu and George Tucker and Ofir Nachum},
      year={2019},
      eprint={1911.11361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{jaques2019way,
      title={Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog},
      author={Natasha Jaques and Asma Ghandeharioun and Judy Hanwen Shen and Craig Ferguson and Agata Lapedriza and Noah Jones and Shixiang Gu and Rosalind Picard},
      year={2019},
      eprint={1907.00456},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{
gulcehre2021addressing,
title={Addressing Extrapolation Error in Deep Offline Reinforcement Learning},
author={Caglar Gulcehre and Sergio G{\'o}mez Colmenarejo and ziyu wang and Jakub Sygnowski and Thomas Paine and Konrad Zolna and Yutian Chen and Matthew Hoffman and Razvan Pascanu and Nando de Freitas},
year={2021},
url={https://openreview.net/forum?id=OCRKCul3eKN}
}

@inproceedings{goo2020you,
  title={You Only Evaluate Once – a Simple Baseline Algorithm for Offline RL},
  author={Wonjoon Goo and Scott Niekum},
  booktitle={Offline Reinforcement Learning Workshop at Neural Information Processing Systems},
  year={2020}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}


@article{nachum2019algaedice,
  title={Algaedice: Policy gradient from arbitrary experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}


@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{Amortila2020AVO,
  title={A Variant of the Wang-Foster-Kakade Lower Bound for the Discounted Setting},
  author={P. Amortila and Nan Jiang and Tengyang Xie},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.01075}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{brockman2016gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@inproceedings{Agarwal2019ReinforcementLT,
  title={Reinforcement Learning: Theory and Algorithms},
  author={Alekh Agarwal and Nan Jiang and S. Kakade},
  year={2019}
}

@misc{Burkhardt2014truncated,
    title={The Truncated Normal Distribution},
    author={John Burkhardt},
    year={2014}
}
