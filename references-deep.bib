@article{henaff2019model,
  title={Model-predictive policy learning with uncertainty regularization for driving in dense traffic},
  author={Henaff, Mikael and Canziani, Alfredo and LeCun, Yann},
  journal={arXiv preprint arXiv:1901.02705},
  year={2019}
}

@inproceedings{CoReyes2018SelfConsistentTA,
  title={Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings},
  author={John D. Co-Reyes and Yuxuan Liu and Abhishek Gupta and Benjamin Eysenbach and Pieter Abbeel and Sergey Levine},
  booktitle={ICML},
  year={2018}
}

@inproceedings{Nachum2018DataEfficientHR,
  title={Data-Efficient Hierarchical Reinforcement Learning},
  author={Ofir Nachum and Shixiang Gu and Honglak Lee and Sergey Levine},
  booktitle={NeurIPS},
  year={2018}
}

@article{Nachum2018NearOptimalRL,
  title={Near-Optimal Representation Learning for Hierarchical Reinforcement Learning},
  author={Ofir Nachum and Shixiang Gu and Honglak Lee and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1810.01257}
}

@article{chandak2019learning,
  title={Learning Action Representations for Reinforcement Learning},
  author={Chandak, Yash and Theocharous, Georgios and Kostas, James and Jordan, Scott and Thomas, Philip S},
  journal={arXiv preprint arXiv:1902.00183},
  year={2019}
}

@inproceedings{higgins2017beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Elsevier}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@article{andrychowicz2018learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={arXiv preprint arXiv:1808.00177},
  year={2018}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, Dave},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  journal={arXiv preprint arXiv:1401.4082},
  year={2014}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{haarnoja2018latent,
  title={Latent space policies for hierarchical reinforcement learning},
  author={Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.02808},
  year={2018}
}

@inproceedings{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{florensa2017stochastic,
  title={Stochastic neural networks for hierarchical reinforcement learning},
  author={Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.03012},
  year={2017}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3540--3549},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  pages={3675--3683},
  year={2016}
}

@article{dulac2015deep,
  title={Deep reinforcement learning in large discrete action spaces},
  author={Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
  journal={arXiv preprint arXiv:1512.07679},
  year={2015}
}

@article{barth2018distributed,
  title={Distributed distributional deterministic policy gradients},
  author={Barth-Maron, Gabriel and Hoffman, Matthew W and Budden, David and Dabney, Will and Horgan, Dan and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:1804.08617},
  year={2018}
}

@article{hafner2018learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  journal={arXiv preprint arXiv:1811.04551},
  year={2018}
}

@article{haarnoja2018softA,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{haarnoja2018softB,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@misc{pytorchrl,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail}},
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM SIGART Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM}
}

@inproceedings{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David and Buesing, Lars and Guez, Arthur and Rezende, Danilo Jimenez and Badia, Adria Puigdomenech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Advances in neural information processing systems},
  pages={5690--5701},
  year={2017}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@article{kaiser2019model,
  title={Model-Based Reinforcement Learning for Atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1809.05214},
  year={2018}
}

@inproceedings{higgins2017darla,
  title={Darla: Improving zero-shot transfer in reinforcement learning},
  author={Higgins, Irina and Pal, Arka and Rusu, Andrei and Matthey, Loic and Burgess, Christopher and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1480--1490},
  year={2017},
  organization={JMLR. org}
}

@article{caselles2018continual,
  title={Continual State Representation Learning for Reinforcement Learning using Generative Replay},
  author={Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Filliat, David},
  journal={arXiv preprint arXiv:1810.03880},
  year={2018}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{ghosh2018learning,
  title={Learning Actionable Representations with Goal-Conditioned Policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{kim2018emi,
  title={EMI: Exploration with Mutual Information Maximizing State and Action Embeddings},
  author={Kim, Hyoungseok and Kim, Jaekyeom and Jeong, Yeonwoo and Levine, Sergey and Song, Hyun Oh},
  journal={arXiv preprint arXiv:1810.01176},
  year={2018}
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, Peter},
  journal={Neural Computation},
  volume={5},
  number={4},
  pages={613--624},
  year={1993},
  publisher={MIT Press}
}

@article{momennejad2017successor,
  title={The successor representation in human reinforcement learning},
  author={Momennejad, Ida and Russek, Evan M and Cheong, Jin H and Botvinick, Matthew M and Daw, Nathaniel Douglass and Gershman, Samuel J},
  journal={Nature Human Behaviour},
  volume={1},
  number={9},
  pages={680},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@inproceedings{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  booktitle={Advances in neural information processing systems},
  pages={4055--4065},
  year={2017}
}

@article{stachenfeld2017hippocampus,
  title={The hippocampus as a predictive map},
  author={Stachenfeld, Kimberly L and Botvinick, Matthew M and Gershman, Samuel J},
  journal={Nature neuroscience},
  volume={20},
  number={11},
  pages={1643},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{liu2019cyclical,
  title={Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing},
  author={Liu, Xiaodong and Gao, Jianfeng and Celikyilmaz, Asli and Carin, Lawrence and others},
  journal={arXiv preprint arXiv:1903.10145},
  year={2019}
}

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and van den Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2721--2730},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}


@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}


@article{osband2019deep,
  author  = {Ian Osband and Benjamin Van Roy and Daniel J. Russo and Zheng Wen},
  title   = {Deep Exploration via Randomized Value Functions},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {124},
  pages   = {1-62},
  url     = {http://jmlr.org/papers/v20/18-339.html}
}

@article{oord2016pixel,
  title={Pixel recurrent neural networks},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1601.06759},
  year={2016}
}

@inproceedings{oord2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  booktitle={Advances in neural information processing systems},
  pages={4790--4798},
  year={2016}
}

@inproceedings{zaheer2018adaptive,
  title={Adaptive methods for nonconvex optimization},
  author={Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9793--9803},
  year={2018}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for Markov decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2-3},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{Kearns1998NearOptimalRL,
  title={Near-Optimal Reinforcement Learning in Polynomial Time},
  author={Michael Kearns and Satinder P. Singh},
  journal={Machine Learning},
  year={1998},
  volume={49},
  pages={209-232}
}

@inproceedings{henaff2019explicit,
  title={Explicit Explore-Exploit Algorithms in Continuous State Spaces},
  author={Henaff, Mikael},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9372--9382},
  year={2019}
}

@inproceedings{Osband2016DeepEV,
  title={Deep Exploration via Bootstrapped DQN},
  author={Ian Osband and Charles Blundell and Alexander Pritzel and Benjamin Van Roy},
  booktitle={NIPS},
  year={2016}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3/4},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@misc{openaifive,
  title={OpenAI Five},
  author={OpenAI},
  year = {2019},
  howpublished = {\url{https://openai.com/five}},
}

@article{Vinyals2019GrandmasterLI,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Oriol Vinyals and Igor Babuschkin and Wojciech Marian Czarnecki and Micha{\"e}l Mathieu and Andrew Joseph Dudzik and Junyoung Chung and Duck Hwan Choi and Richard W. Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and Laurent Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander Sasha Vezhnevets and R{\'e}mi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom Le Paine and Caglar Gulcehre and Ziyu Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario W{\"u}nsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy P. Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  year={2019},
  pages={1-5}
}

@article{Silver2018AGR,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy P. Lillicrap and Karen Simonyan and Demis Hassabis},
  journal={Science},
  year={2018},
  volume={362},
  pages={1140-1144}
}

@inproceedings{Mnih2016AsynchronousMF,
  title={Asynchronous Methods for Deep Reinforcement Learning},
  author={Volodymyr Mnih and Adri{\`a} Puigdom{\`e}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  booktitle={ICML},
  year={2016}
}

@article{OpenAI2019SolvingRC,
  title={Solving Rubik's Cube with a Robot Hand},
  author={OpenAI and Ilge Akkaya and Marcin Andrychowicz and Maciek Chociej and Mateusz Litwin and Bob McGrew and Arthur Petron and Alex Paino and Matthias Plappert and Glenn Powell and Raphael Ribas and Jonas Schneider and Nikolas Tezak and Jadwiga Tworek and Peter Welinder and Lilian Weng and Qi-Ming Yuan and Wojciech Zaremba and Lefei Zhang},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.07113}
}

@incollection{Tang2017Exploration,
title = {\#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning},
author = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Xi Chen, OpenAI and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {2753--2762},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@article{Auer2008NearoptimalRB,
  title={Near-optimal Regret Bounds for Reinforcement Learning},
  author={Peter Auer and Thomas Jaksch and Ronald Ortner},
  journal={J. Mach. Learn. Res.},
  year={2008},
  volume={11},
  pages={1563-1600}
}

@article{Stadie2015IncentivizingEI,
  title={Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models},
  author={Bradly C. Stadie and Sergey Levine and Pieter Abbeel},
  journal={ArXiv},
  year={2015},
  volume={abs/1507.00814}
}

@inproceedings{Kapturowski2019RecurrentER,
  title={Recurrent Experience Replay in Distributed Reinforcement Learning},
  author={Steven Kapturowski and Georg Ostrovski and John Quan and R{\'e}mi Munos and Will Dabney},
  booktitle={ICLR},
  year={2019}
}

@article{Moore1993PrioritizedSR,
  title={Prioritized Sweeping: Reinforcement Learning with Less Data and Less Time},
  author={Andrew W. Moore and Christopher G. Atkeson},
  journal={Machine Learning},
  year={1993},
  volume={13},
  pages={103-130}
}

@article{Peng1993EfficientLA,
  title={Efficient learning and planning within the Dyna framework},
  author={J. Peng and R. Williams},
  journal={IEEE International Conference on Neural Networks},
  year={1993},
  pages={168-174 vol.1}
}

@article{Abdolmaleki2018MaximumAP,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abbas Abdolmaleki and Jost Tobias Springenberg and Yuval Tassa and R{\'e}mi Munos and Nicolas Manfred Otto Heess and Martin A. Riedmiller},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.06920}
}

@article{Abdolmaleki2018RelativeER,
  title={Relative Entropy Regularized Policy Iteration},
  author={Abbas Abdolmaleki and Jost Tobias Springenberg and Jonas Degrave and Steven Bohez and Yuval Tassa and Dan Belov and Nicolas Manfred Otto Heess and Martin A. Riedmiller},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02256}
}

@inproceedings{Schulman2015TrustRP,
  title={Trust Region Policy Optimization},
  author={John Schulman and Sergey Levine and Pieter Abbeel and Michael I. Jordan and Philipp Moritz},
  booktitle={ICML},
  year={2015}
}

@article{Fujimoto2019BenchmarkingBD,
  title={Benchmarking Batch Deep Reinforcement Learning Algorithms},
  author={Scott Fujimoto and Edoardo Conti and Mohammad Ghavamzadeh and Joelle Pineau},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01708}
}

@inproceedings{Lange2012BatchRL,
  title={Batch Reinforcement Learning},
  author={Sascha Lange and Thomas Gabel and Martin A. Riedmiller},
  booktitle={Reinforcement Learning},
  year={2012}
}

@article{Jaques2019WayOB,
  title={Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog},
  author={Natasha Jaques and Asma Ghandeharioun and Judy Hanwen Shen and Craig Ferguson and {\`A}gata Lapedriza and Noah J. Jones and Shixiang Gu and Rosalind W. Picard},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.00456}
}

@article{Kumar2019StabilizingOQ,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.00949}
}

@inproceedings{Fujimoto2018OffPolicyDR,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Scott Fujimoto and David Meger and Doina Precup},
  booktitle={ICML},
  year={2018}
}

@article{Agarwal2019StrivingFS,
  title={Striving for Simplicity in Off-policy Deep Reinforcement Learning},
  author={Rishabh Agarwal and Dale Schuurmans and Mohammad Norouzi},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.04543}
}

@inproceedings{
    Siegel2020Keep,
    title={Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning},
    author={Noah Siegel and Jost Tobias Springenberg and Felix Berkenkamp and Abbas Abdolmaleki and Michael Neunert and Thomas Lampe and Roland Hafner and Nicolas Heess and Martin Riedmiller},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=rke7geHtwH}
}

@article{Brafman2002RMAXA,
  title={R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning},
  author={R. Brafman and Moshe Tennenholtz},
  journal={J. Mach. Learn. Res.},
  year={2002},
  volume={3},
  pages={213-231}
}

@inproceedings{
    Taiga2020On,
    title={On Bonus Based Exploration Methods In The Arcade Learning Environment},
    author={Adrien Ali Taiga and William Fedus and Marlos C. Machado and Aaron Courville and Marc G. Bellemare},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=BJewlyStDr}
}

@article{Dean2020SeeHE,
  title={See, Hear, Explore: Curiosity via Audio-Visual Association},
  author={Victoria Dean and Shubham Tulsiani and Abhinav Gupta},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.03669}
}

@inproceedings{Machado2020CountBasedEW,
  title={Count-Based Exploration with the Successor Representation},
  author={Marlos C. Machado and Marc G. Bellemare and Michael H. Bowling},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{Kolter2009NearBayesianEI,
  title={Near-Bayesian exploration in polynomial time},
  author={J. Z. Kolter and A. Ng},
  booktitle={ICML '09},
  year={2009}
}

@article{Dabney2020TemporallyExtendedE,
  title={Temporally-Extended $\epsilon$-Greedy Exploration},
  author={Will Dabney and Georg Ostrovski and A. Barreto},
  journal={arXiv: Learning},
  year={2020}
}

@inproceedings{Hasselt2016DeepRL,
  title={Deep Reinforcement Learning with Double Q-Learning},
  author={H. V. Hasselt and A. Guez and D. Silver},
  booktitle={AAAI},
  year={2016}
}

@article{Rashid2020OptimisticEE,
  title={Optimistic Exploration even with a Pessimistic Initialisation},
  author={Tabish Rashid and B. Peng and Wendelin B{\"o}hmer and S. Whiteson},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.12174}
}

@misc{neunert2020continuousdiscrete,
      title={Continuous-Discrete Reinforcement Learning for Hybrid Control in Robotics},
      author={Michael Neunert and Abbas Abdolmaleki and Markus Wulfmeier and Thomas Lampe and Jost Tobias Springenberg and Roland Hafner and Francesco Romano and Jonas Buchli and Nicolas Heess and Martin Riedmiller},
      year={2020},
      eprint={2001.00449},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Badia2020NeverGU,
  title={Never Give Up: Learning Directed Exploration Strategies},
  author={Adri{\`a} Puigdom{\`e}nech Badia and P. Sprechmann and Alex Vitvitskyi and Daniel Guo and B. Piot and Steven Kapturowski and O. Tieleman and Mart{\'i}n Arjovsky and A. Pritzel and Andew Bolt and Charles Blundell},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.06038}
}

@inproceedings{Riedmiller2018LearningBP,
  title={Learning by Playing - Solving Sparse Reward Tasks from Scratch},
  author={Martin A. Riedmiller and Roland Hafner and T. Lampe and Michael Neunert and J. Degrave and T. Wiele and V. Mnih and N. Heess and Jost Tobias Springenberg},
  booktitle={ICML},
  year={2018}
}

@inproceedings{Abdolmaleki2020ADV,
  title={A Distributional View on Multi-Objective Policy Optimization},
  author={Abbas Abdolmaleki and Sandy H. Huang and Leonard Hasenclever and Michael Neunert and H. Song and Martina Zambelli and M. F. Martins and Nicolas Heess and Raia Hadsell and Martin A. Riedmiller},
  booktitle={ICML},
  year={2020}
}

@inproceedings{Whitney2020DynamicsawareE,
  title={Dynamics-aware Embeddings},
  author={William F. Whitney and Rajat Agarwal and Kyunghyun Cho and Abhinav Gupta},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{Jaksch2008NearoptimalRB,
  title={Near-optimal Regret Bounds for Reinforcement Learning},
  author={T. Jaksch and R. Ortner and P. Auer},
  booktitle={J. Mach. Learn. Res.},
  year={2008}
}

@inproceedings{Strehl2006PACMR,
  title={PAC model-free reinforcement learning},
  author={Alexander L. Strehl and L. Li and Eric Wiewiora and J. Langford and M. Littman},
  booktitle={ICML '06},
  year={2006}
}

@inproceedings{Jin2018IsQP,
  title={Is Q-learning Provably Efficient?},
  author={C. Jin and Zeyuan Allen-Zhu and S{\'e}bastien Bubeck and Michael I. Jordan},
  booktitle={NeurIPS},
  year={2018}
}

@article{Fortunato2018NoisyNF,
  title={Noisy Networks for Exploration},
  author={Meire Fortunato and Mohammad Gheshlaghi Azar and B. Piot and Jacob Menick and Ian Osband and A. Graves and Vlad Mnih and R{\'e}mi Munos and Demis Hassabis and O. Pietquin and Charles Blundell and S. Legg},
  journal={ArXiv},
  year={2018},
  volume={abs/1706.10295}
}

@article{Plappert2018ParameterSN,
  title={Parameter Space Noise for Exploration},
  author={Matthias Plappert and Rein Houthooft and Prafulla Dhariwal and S. Sidor and Richard Y. Chen and Xi Chen and T. Asfour and P. Abbeel and Marcin Andrychowicz},
  journal={ArXiv},
  year={2018},
  volume={abs/1706.01905}
}

@article{Popov2017DataefficientDR,
  title={Data-efficient Deep Reinforcement Learning for Dexterous Manipulation},
  author={I. Popov and N. Heess and T. Lillicrap and Roland Hafner and Gabriel Barth-Maron and Matej Vecer{\'i}k and T. Lampe and Y. Tassa and T. Erez and Martin A. Riedmiller},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.03073}
}

@article{Schoknecht2003ReinforcementLO,
  title={Reinforcement learning on explicitly specified time scales},
  author={Ralf Schoknecht and Martin A. Riedmiller},
  journal={Neural Computing \& Applications},
  year={2003},
  volume={12},
  pages={61-80}
}

@inproceedings{Bellemare2015TheAL,
  title={The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)},
  author={Marc G. Bellemare and Yavar Naddaf and J. Veness and Michael Bowling},
  booktitle={IJCAI},
  year={2015}
}

@book{Sutton2018ReinforcementLA,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}}

@article{Schaul2016PrioritizedER,
  title={Prioritized Experience Replay},
  author={Tom Schaul and John Quan and Ioannis Antonoglou and D. Silver},
  journal={CoRR},
  year={2016},
  volume={abs/1511.05952}
}

@article{Vehtari2015ParetoSI,
  title={Pareto Smoothed Importance Sampling},
  author={A. Vehtari and A. Gelman and J. Gabry},
  journal={arXiv: Computation},
  year={2015}
}

@misc{pytorch_sac,
  author = {Yarats, Denis and Kostrikov, Ilya},
  title = {Soft Actor-Critic (SAC) implementation in PyTorch},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/denisyarats/pytorch_sac}},
}

@article{Henderson2012NormalRB,
  title={Normal reference bandwidths for the general order, multivariate kernel density derivative estimator},
  author={D. Henderson and Christopher F. Parmeter},
  journal={Statistics \& Probability Letters},
  year={2012},
  volume={82},
  pages={2198-2205}
}

@article{keops,
  author  = {Benjamin Charlier and Jean Feydy and Joan Alexis Glaunès and François-David Collin and Ghislain Durif},
  title   = {Kernel Operations on the GPU, with Autodiff, without Memory Overflows},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {74},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v22/20-275.html}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018},
}

@software{flax2020github,
  author = {Jonathan Heek and Anselm Levskaya and Avital Oliver and Marvin Ritter and Bertrand Rondepierre and Andreas Steiner and Marc van {Z}ee},
  title = {{F}lax: A neural network library and ecosystem for {JAX}},
  url = {http://github.com/google/flax},
  version = {0.3.4},
  year = {2020},
}

@inproceedings{Paszke2019PyTorchAI,
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author={Adam Paszke and S. Gross and Francisco Massa and A. Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Z. Lin and N. Gimelshein and L. Antiga and Alban Desmaison and Andreas K{\"o}pf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
  booktitle={NeurIPS},
  year={2019}
}

